---
title: 'HR Analytics: Job Change of Data Scientists'
author: "Rodrigo Moraes Kunrath"
date: "7/25/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	fig.height = 3.5, 
	fig.width = 7
)
```

# Introduction

## Overview

The goal of this project is to predict whether an employee desires to leave his current job. It has been developed with R and is part of the Data Science's Capstone project from HarvardX.

The dataset was downloaded from a Kaggle proposed task and it is available in *https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists*. This project used only the *aug_train.csv* original file that was stored as *data/dataset.csv*. The whole project can be obtained through the GitHub repositoty in *https://github.com/rmkunrath/hr_analytics*.

The context that the dataset was created is that it comes from a poll generated by a company which is active in Big Data and Data Science and wants to hire data scientists among people who successfully pass some courses which were conducted by the company. The company wants to know which of these candidates are really looking to work for them after training. Information related to demographics, education, experience are from candidates signup and enrollment. In this project all enrollees were considered employees.

The general idea is to understand the factors that lead a person to leave their current job using models that use the current credentials, demographics, experience data. The final objective is to create a machine learning algorithim that predicts the employee desire to leave.

To achieve this goal, the data was imported, explored, wrangled, divided in training and testing datasets. Machine learning models were proposed with a subset of the training dataset and evaluated with another subset of the training. Finally a model was selected and applied to the testing dataset.

## The dataset

```{r warning=FALSE, include=FALSE}
# loading libraries and ensuring repetibility

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(broom)) install.packages("broom", repos = "http://cran.us.r-project.org")
if(!require(mgcv)) install.packages("mgcv", repos = "http://cran.us.r-project.org")

set.seed(1, sample.kind="Rounding")

# IMPORTING THE DATA

dt <- read.csv("data/dataset.csv", na.strings="")
```

The dataset has 19158 entries and is composed of the following 14 features:

* enrollee_id : Unique ID for candidate
* city: City code
* city_ development _index : Developement index of the city (scaled)
* gender: Gender of candidate
* relevent_experience: Relevant experience of candidate
* enrolled_university: Type of University course enrolled if any
* education_level: Education level of candidate
* major_discipline :Education major discipline of candidate
* experience: Candidate total experience in years
* company_size: No of employees in current employer's company
* company_type : Type of current employer
* lastnewjob: Difference in years between previous job and current job
* training_hours: training hours completed
* target: 0 – Not looking for job change, 1 – Looking for a job change

The collumn target is the value we are trying to understand and predict. 

Bellow a summary of the dataset is shown:

```{r echo=TRUE}
summary(dt)
```

# Methods

In this section the methods applied to gain insight as well as the modeling developed are going to be described.

## Data Exploration

The dataset is composed of 19158 entries and has 14 features. Its sumary has been shown in the *Dataset* section. The target is the feature this project wishes to predict and gain insight, it has a mean rate of about 25% and, in other words, it means that one fourth of the employees are looking for a new job.

```{r}
dt %>% summarise("Target mean rate" = mean(target))  %>% knitr::kable()
dt %>% ggplot(aes(target)) + geom_bar() +
  xlab("Target") + ylab("Total entries")
```

```{r include=FALSE}
mu_target <- mean(dt$target)
```

To better understand how the other features relate to the target, the desire that an employee has to look for a new job, a series of plots comparing the percentage distribution of this very features is going to be presented faceted by the target. Simply put, the distribution in the left contain data from employees that are not looking for a new job while the distribution in the right contains the employees that are looking for new positions.

When comparing the gender, there is a higher inclination of NAs with target 1. It is also noticiable that male employees consist of the majority of the dataset. Can men be concealing their gender during the polls when they desire to look for a new job?

```{r}
dt %>% ggplot(aes(x= gender,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  geom_text(aes(label = scales::percent(..prop..),
                 y= ..prop.. ), stat= "count", vjust = -.5) +
  labs(y = "Percent", fill="Gender") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent)
```

A similar behavior of higher NA values to target 1 is observed when comparing the company size and company type.

```{r}
# company_size X target
dt %>% ggplot(aes(x= company_size,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  labs(y = "Percent", fill="company_size") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Company Size") +
  theme(axis.text.x = element_text(angle = 90))

# company_type X target
dt %>%
  ggplot(aes(x= company_type,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  labs(y = "Percent", fill="company_type") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Company Type") +
  theme(axis.text.x = element_text(angle = 90))
```

Other features, like the training hours, do not seem to interfere with the target at all as there is no substantial difference in distribution shapes.

```{r}
# training_hours*10 X target
dt %>% ggplot(aes(x= as.integer(training_hours/20),  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  labs(y = "Percent", fill="Training hours * 20") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Training hours / 20") 
```

Another insight that data exploration give us is that, while employees with no relevant experience wish to work with Data Science, the ones with more than 15 years of experience are looking for new horizons. The persona that stars to build is someone with no relevant experience in Data Science but with more than 15 years in the market.

```{r}
# relevent_experience X target
dt %>%
  ggplot(aes(x= relevent_experience,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  geom_text(aes(label = scales::percent(..prop..),
                y= ..prop.. ), stat= "count", vjust = -.5) +
  labs(y = "Percent", fill="relevent_experience") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Relevant experience") +
  theme(axis.text.x = element_text(angle = 90))

# experience X target
dt %>%
  mutate(experience = as.numeric(experience)) %>%
  ggplot(aes(x= experience,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  labs(y = "Percent", fill="experience") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Experience (years)") 
```

There is no great change in the last new job feature regarding the target.

```{r}
# last_new_job X target
dt %>%
  ggplot(aes(x= last_new_job,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  # geom_text(aes(label = scales::percent(..prop..),
  #               y= ..prop.. ), stat= "count", vjust = -.5) +
  labs(y = "Percent", fill="Last new job") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Last new job") 
```

Regarding education, the fact that an employee is a graduate and enrolled in a full time course seem to alter the tendency to look for a new job. It can also be said that the fact that an employee is not enrolled in any course will reduce its tendency to look for a new job. The major discipline doesn't seem to affect much the inclination to target 1.

```{r}
# education_level X target
dt %>%
  ggplot(aes(x= education_level,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  # geom_text(aes(label = scales::percent(..prop..),
  #               y= ..prop.. ), stat= "count", vjust = -.5) +
  labs(y = "Percent", fill="education_level") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Education level")  +
  theme(axis.text.x = element_text(angle = 90))

# enrolled_university X target
dt %>%
  ggplot(aes(x= enrolled_university,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  # geom_text(aes(label = scales::percent(..prop..),
  #               y= ..prop.. ), stat= "count", vjust = -.5) +
  labs(y = "Percent", fill="enrolled_university") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Enrolled University")  +
  theme(axis.text.x = element_text(angle = 90))

# major_discipline X target
dt %>%
  ggplot(aes(x= major_discipline,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  labs(y = "Percent", fill="major_discipline") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Major Discipline")  +
  theme(axis.text.x = element_text(angle = 90))
```

Finally, when analysing the demographic aspect it is clear that cities with lower development index have a higher rate of employees looking for new jobs. The target rate is way bigger than the 25% rate of the whole dataset.

```{r}
# city_development_index*10 X target
dt %>% ggplot(aes(x= as.integer(city_development_index*10),  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  labs(y = "Percent", fill="city_development_index hours * 10") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("City DI * 10") 

# city X target
tab <- dt %>% 
  group_by(city) %>%
  summarise(mean_target = mean(target), entries = sum(city != 0), HDI = mean(city_development_index)) %>%
  filter(mean_target > mu_target & entries > 50) %>%
  arrange(desc(mean_target)) %>%
  head(10)

colnames(tab) <- c("City", "Mean target", "Entries count", "HDI")
tab %>%  knitr::kable()

rm(tab)
```

## Data Wrangling

With the insight gained from data exploration, it is clear that the NA values cannot be disregarded for catagorical data from this dataset. With this in mind, categorical NAs were changed to a category called "ND" (not disclosed). 

The levels of the categorical data were also factored and ordered using the insight gained. The features experience and last_new_job were wrangled and converted to numeric.

Also, a new column was added with the city target mean. Numerical NAs were omitted.

```{r include=FALSE}
dt <- read_csv("data/dataset.csv")
dt[is.na(dt)] <- "ND"

dt$gender <- factor(dt$gender)

dt$relevent_experience <- factor(dt$relevent_experience) %>% ordered()

dt$enrolled_university <- factor(dt$enrolled_university, 
                                 levels = c("ND", "Full time course", "Part time course",
                                            "no_enrollment")) %>% ordered()

dt$education_level <- factor(dt$education_level,
                             levels = c("Graduate","Masters","High School",
                                        "Phd", "Primary School", "ND")) %>% ordered()

dt$major_discipline <- factor(dt$major_discipline) %>% ordered()

dt[dt == ">20"] <- "21"
dt[dt == "<1"] <- "0"
dt$experience <- as.numeric(dt$experience)

dt$company_size <- factor(dt$company_size,
                          levels = c("ND", "<10", "10/49", "50-99", "100-500", "500-999", "1000-4999",
                                     "5000-9999", "10000+")) %>% ordered()



# From data exploration, it seems that employees from Pvt Ltd moved to ND. That's the reason for reordering
dt$company_type <- factor(dt$company_type,
                          levels = c("ND", "Pvt Ltd", "Public Sector", "Other",
                                     "NGO", "Early Stage Startup", "Funded Startup"))

dt[dt == ">4"] <- "5"
dt[dt == "never"] <- "0"
dt$last_new_job <- as.numeric(dt$last_new_job)


# dt$target <- factor(dt$target)

dt_city_rate <- dt %>% 
  group_by(city) %>% 
  summarise(city_target_rating = mean(target))

# Adding the column
dt <- left_join(dt, dt_city_rate, by = "city")

summary(dt)

# removing NAs
dt <- na.omit(dt)
dt$city <- NULL
```

Using the new wrangling applied, new plots were created. These plots confirm that, without considering NAs, there is no significant distribution change in target with the last new job and companie size.

```{r}
# company_size X target
dt %>% 
  filter(company_size != "ND") %>%
  ggplot(aes(x= company_size,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  # geom_text(aes(label = scales::percent(..prop..),
  #               y= ..prop.. ), stat= "count", vjust = -.5) +
  labs(y = "Percent", fill="company_size") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Company Size")  +
  theme(axis.text.x = element_text(angle = 90))

# last_new_job X target
dt %>%
  ggplot(aes(x= last_new_job,  group=target)) + 
  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count", show.legend = FALSE) +
  # geom_text(aes(label = scales::percent(..prop..),
  #               y= ..prop.. ), stat= "count", vjust = -.5) +
  labs(y = "Percent", fill="Last new job") +
  facet_grid(~target) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Last new job") 
```

## Data Splitting

To model the machine learning algorithms the data has been split twice. Firstly 10% of the data was randomly reserved for the final evaluation. The remaining 90% was again split, this time reserving 10% of it to testing development and 90% of it to training.

```{r include=FALSE}
# SEPARATING IN TRAIN AND TEST

# Leaving 10% of the data to test and creating test and train set
test_index <- createDataPartition(y = dt$target, times = 1,
                                  p = 0.10, list = FALSE)
train_set <- dt %>% slice(-test_index)
test_set_final <- dt %>% slice(test_index)

rm(test_index)

# SEPARATING THE TRAIN IN TWO

# Leaving 10% of the data to test and creating test and train set
test_index <- createDataPartition(y = train_set$target, times = 1,
                                  p = 0.10, list = FALSE)
train_set_model <- train_set %>% slice(-test_index)
test_set_development <- train_set %>% slice(test_index)

rm(test_index)
```


## Modeling

In order to model the machine learning algorithm a table to evaluate and compare the techniques was created. It is composed of the method, accuracy, sensitivity, specificity and F1 score.

### Predicting the target rate

As a starting point, the metrics of just guessing the target with the dataset mean rate was used. Bellow the results are shown.

```{r}
# Just guessing the value.
# Determining a mean rate and predict it
p <- mean(as.numeric(train_set_model$target))

n <- nrow(test_set_development)

y_hat <- sample(c(1, 0), n, replace = TRUE, prob = c(p,1-p))

# Doesn't have a good specificity, in other words the proportion of negatives is low and the model doesn't predict well when the employee wishes to stay.
cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- data_frame(Method = "Guessing target rate", 
                      Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                      Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                      Specificity = round(as.double(cm$byClass["Specificity"]),3),
                      F1 = round(as.double(cm$byClass["F1"]),3))

results %>% knitr::kable()
```


### Linear Regression

The first linear regression considers the company_size, company_type, education_level, relevent_experience, experience, enrolled_university and city_development_index features. When the predicted value was higher than 0.5 the target was changed to 1, otherwise it was changed to 0.

A second linear regression was made. This time including also the city mean target rate. Below are the results.

```{r}
lm_fit1 <- train_set_model %>%
  lm(target ~ company_size + company_type + education_level + 
       relevent_experience + experience + enrolled_university +
       city_development_index, data=.)

y_hat_linear_numeric <- predict(lm_fit1, newdata = test_set_development, type = "response")

y_hat <- ifelse(y_hat_linear_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="Linear regression", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))

lm_fit2 <- train_set_model %>%
  lm(target ~ . , data=.)


y_hat_linear_numeric <- predict(lm_fit2, newdata = test_set_development, type = "response")

y_hat <- ifelse(y_hat_linear_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="Complete Linear regression", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))
results %>% knitr::kable()
```

Although the first linear regression increased substantially the F1 score and accuracy, it had a slighter smaller specificity. Considering the city target rate seems to present a more robust approach with its higher specificity, once positive calls tend to actually have a higher chance of being positive.

### GAM Smoothing and Logistic Regression

Both GAM Smoothing and Logistic regression do not improve the specificity and F1 Score in a way that the computational effort is worth.

```{r}
gam_fit <- train_set_model %>%
  gam(target ~ company_size + company_type + education_level + 
        relevent_experience + experience + enrolled_university +
        city_development_index + city_target_rating, data=.)

y_hat_gam_numeric <- predict(gam_fit, newdata = test_set_development)

y_hat <- ifelse(y_hat_gam_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="GAM Smooth", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))
```


```{r}
fit_glm <- train(target ~ . , "glm", data = train_set_model)

y_hat_glm_numeric <- predict(fit_glm, newdata = test_set_development)

y_hat <- ifelse(y_hat_glm_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="Logistic Regression", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))
results %>% knitr::kable()
```


### Random Forest

The final approach is through a random forest algorithm with the *RBorist* package. In the graphics below it is shown that the features city_target_rating, city_development_index and company_size can be good predictors for the target, mainly when considering the NDs values.

```{r}
train_set_model %>% ggplot(aes(city_development_index, company_size, color = target)) +
   geom_point(alpha = 0.2)
train_set_model %>% ggplot(aes(city_target_rating, company_size, color = target)) +
  geom_point(alpha = 0.2)
train_set_model %>% ggplot(aes(city_development_index, city_target_rating, color = target)) +
  geom_point(alpha = 0.2)
```

Four models have been created and their result can be seen at next table. There has been a great improvement in specificity. Curiously, when considering the three features at the same time the model performed worse in terms of specificity.

```{r}
fit_rf1 <- train(target ~  city_development_index +
                  company_size, "Rborist", data = train_set_model)

y_hat_rf_numeric <- predict(fit_rf1, newdata = test_set_development)

y_hat <- ifelse(y_hat_rf_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="Random Forest: Company Size X City DI", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))

fit_rf2 <- train(target ~  city_target_rating +
                  company_size, "Rborist", data = train_set_model)

y_hat_rf_numeric <- predict(fit_rf2, newdata = test_set_development)

y_hat <- ifelse(y_hat_rf_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="Random Forest: City Target Rating x Company Size", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))


fit_rf3 <- train(target ~  city_target_rating +
                   city_development_index , "Rborist", data = train_set_model)

y_hat_rf_numeric <- predict(fit_rf3, newdata = test_set_development)

y_hat <- ifelse(y_hat_rf_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="Random Forest: City Target Rating x City DI", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))


fit_rf4 <- train(target ~  city_target_rating +
                   city_development_index + company_size, "Rborist", data = train_set_model)

y_hat_rf_numeric <- predict(fit_rf4, newdata = test_set_development)

y_hat <- ifelse(y_hat_rf_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_development$target))

results <- bind_rows(results, data_frame(Method="Random Forest: City Target Rating x City DI x Company Size", 
                                         Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                                         Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                                         Specificity = round(as.double(cm$byClass["Specificity"]),3),
                                         F1 = round(as.double(cm$byClass["F1"]),3)))
results %>% knitr::kable()
```

# Results

The Random Forest: Company Size X City DI model was chosen. It had the best specificity while also keeping a solid F1 score and accuracy. Below the final result is presented.

```{r}
# EVALUATING THE MODEL

y_hat_numeric <- predict(fit_rf1, newdata = test_set_final)

y_hat <- ifelse(y_hat_numeric > 0.5, 1, 0)

cm <- confusionMatrix(data = factor(y_hat), reference = factor(test_set_final$target))

results_final <- data_frame(Method = "Random Forest: City Target Rating x Company Size", 
                      Accuracy = round(as.double(cm$overall["Accuracy"]),3),
                      Sensitivity = round(as.double(cm$byClass["Sensitivity"]),3),
                      Specificity = round(as.double(cm$byClass["Specificity"]),3),
                      F1 = round(as.double(cm$byClass["F1"]),3))

results_final %>% knitr::kable()
```


# Conclusion

Using Data Science a better approach was built to predict, with the curent dataset, when an employee is looking for a new job. The machine learning modelling created outperformed greatly the random guess of 25%.

Using the data presented, the persona built when thinking about one enrolle that has all the trends of someone looking for a new job in data science would be a person that
* Live in a city with low DI
* Is full time enrolled in a university in a graduation course
* Have no relevant experience in Data Science
* Have more than 13 years of experience
* Doesn't state the company size or type

A great limitation of the method chosen is that other features than the Company Size and City DI were not used. In data exploration it has been seen that whithout the NAs/NDs values the company size shouldn't be taken into accout. Another is that all enrollees were considered employees. In the end, the project is considering the fact that people that are looking for a new job are more concealing when given their information in polls.

A future work would be determining the primary components (PCA) that motivate one enrollee to look for a new job.
